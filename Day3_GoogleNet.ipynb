{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "slim=tf.contrib.slim\n",
    "'''\n",
    "相当于把tf.truncated_normal_initializer重新包装了一层\n",
    "默认生成均值为0.0，标准差为输入值的初始化器\n",
    "'''\n",
    "trunc_normal = lambda stddev:tf.truncated_normal_initializer(0.0,stddev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "生成默认参数\n",
    "tf.GraphKeys.UPDATE_OPS的目的：\n",
    "https://stackoverflow.com/questions/48260394/whats-the-differences-between-tf-graphkeys-trainable-variables-and-tf-graphkeys\n",
    "'''\n",
    "def inception_v3_arg_scope(weight_decay=0.00004, # L2正则项的weight-decay，详见weight-decay具体含义\n",
    "                           stddev=0.1,\n",
    "                           batch_norm_var_collection='moving_vars'):\n",
    "    batch_norm_params = {\n",
    "        'decay':0.9997,\n",
    "        'epsilon':0.001,\n",
    "        'updates_collections':tf.GraphKeys.UPDATE_OPS, # 这个是啥 拿到图中所有需要被更新的ops的名称,？\n",
    "        'variables_collections':{\n",
    "            'beta':None,\n",
    "            'gamma':None,\n",
    "            'moving_mean':[batch_norm_var_collection],\n",
    "            'moving_variance':[batch_norm_var_collection],\n",
    "        }\n",
    "    }\n",
    "    with slim.arg_scope([slim.conv2d,slim.fully_connected],\n",
    "                        weights_regularizer=slim.l2_regularizer(weight_decay)):\n",
    "        with slim.arg_scope([slim.conv2d],\n",
    "                            weights_initializer=tf.truncated_normal_initializer(stddev=stddev),\n",
    "                            activation_fn=tf.nn.relu,\n",
    "                            normalizer_params = batch_norm_params\n",
    "                           ) as sc:\n",
    "            return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3_base(inputs,scope=None):\n",
    "    # 保存关键节点\n",
    "    end_points = {}\n",
    "    with tf.variable_scope(scope,'InceptionV3_3',[inputs]):\n",
    "        '''\n",
    "            设置卷积/最大池化/平均池化的默认步长为1,padding模式为VALID\n",
    "            即，设置超参数\n",
    "            \n",
    "            算是设置了初始的几层卷积层\n",
    "        '''\n",
    "        with slim.arg_scope([slim.conv2d,\n",
    "                             slim.max_pool2d,\n",
    "                             slim.avg_pool2d],\n",
    "                             stride=1,\n",
    "                             padding='VALID'):\n",
    "            net = slim.conv2d(inputs,32,[3,3],stride=2,scope='Conv2d_1a_3x3_1')\n",
    "            net = slim.conv2d(net,32,[3,3],scope='Conv2d_2a_3x3_1')\n",
    "            net = slim.conv2d(net,64,[3,3],padding='SAME',scope='Conv2d_2b_3x3_1')\n",
    "            \n",
    "            net = slim.max_pool2d(net, [3, 3], stride=2, scope='MaxPool_3a_3x3_1')\n",
    "            net = slim.conv2d(net, 80, [1, 1], scope='Conv2d_3b_1x1_1')\n",
    "            net = slim.conv2d(net, 192, [3, 3], scope='Conv2d_4a_3x3_1')\n",
    "            net = slim.max_pool2d(net, [3, 3], stride=2, scope='MaxPool_5a_3x3_1')\n",
    "        \n",
    "        '''\n",
    "            设置卷积/最大池化/平均池化的默认步长为1,padding模式为SAME\n",
    "        '''\n",
    "        with slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d],\n",
    "                           stride=1,\n",
    "                           padding='SAME'):\n",
    "            '''\n",
    "                第一个inception模组的第一个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_5b'):\n",
    "                # branch 1：1*1*64\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,64,[1,1],scope='Conv2d_0a_1x1')\n",
    "                # branch 2: 1*1*48 接5*5*64\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,48,[1,1],scope='Conv2d_0a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,64,[5,5],scope='Conv2d_0b_5x5')\n",
    "                # branch 3: 1*1*64 接 3*3*96 3*3*96\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,64,[1,1],scope='Conv2d_0a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,96,[3,3],scope='Conv2d_0b_3x3')\n",
    "                    branch_2 = slim.conv2d(branch_2,96,[3,3],scope='Conv2d_0c_3x3')\n",
    "                # branch 4: 3*3 average pooling,1*1*32\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_0a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,32,[1,1],scope='Conv2d_0b_1x1')\n",
    "                # concate all the 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            '''\n",
    "                第一个inception模组的第二个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_5c'):\n",
    "                # branch 1:1*1*64\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,64,[1,1],scope='Conv2d_0a_1x1')\n",
    "                # branch 2:1*1*48,5*5*64\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,48,[1,1],scope='Conv2d_0a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,64,[5,5],scope='Conv2d_0b_5x5')\n",
    "                # branch 3:1*1*64,3*3*96 3*3*96\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,64,[1,1],scope='Conv2d_0a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,96,[3,3],scope='Conv2d_0b_3x3')\n",
    "                    branch_2 = slim.conv2d(branch_2,96,[3,3],scope='Conv2d_0c_3x3')\n",
    "                # branch 4: 3*3 avg pooling 1*1*64\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_0a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,64,[1,1],scope='Conv2d_0b_1x1')\n",
    "                # concate all the 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            '''\n",
    "                第一个inception模组的第三个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_5d'):\n",
    "                # branch 1:1*1*64\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,64,[1,1],scope='Conv2d_0a_1x1')\n",
    "                # branch 2:1*1*48,5*5*64\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,48,[1,1],scope='Conv2d_0a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,64,[5,5],scope='Conv2d_0b_5x5')\n",
    "                # branch 3:1*1*64,3*3*96 3*3*96\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,64,[1,1],scope='Conv2d_0a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,96,[3,3],scope='Conv2d_0b_3x3')\n",
    "                    branch_2 = slim.conv2d(branch_2,96,[3,3],scope='Conv2d_0c_3x3')\n",
    "                # branch 4: 3*3 avg pooling 1*1*64\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_0a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,64,[1,1],scope='Conv2d_0b_1x1')\n",
    "                # concate all the 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            \n",
    "            '''\n",
    "                第二个inception模组的预分支\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_6a'):\n",
    "                # branch 1 : 3*3*384,strides=2,padding=valid\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,384,[3,3],stride=2,padding='VALID',scope='Conv2d_1a_1x1')\n",
    "                # branch 2 : 1*1*64,3*3*96 *2\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,64,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,96,[3,3],scope='Conv2d_1b_3x3')\n",
    "                    # strid=2,padding=valid\n",
    "                    branch_1 = slim.conv2d(branch_1,96,[3,3],stride=2,padding='VALID',scope='Conv2d_1c_3x3')\n",
    "                # branch 3 : 3*3 max pool strid=2,padding=valid;\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.max_pool2d(net,[3,3],stride=2,padding='VALID',scope='MaxPool_1a_3x3')\n",
    "                # concate all 3 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2],axis=3)\n",
    "            '''\n",
    "                第二个inception模组的第二个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_6b'):\n",
    "                # branch 1 1*1*192\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,192,[1,1],scope='Conv2d_1a_1x1')\n",
    "                # branch 2 1*1*128,1*7*128,7*1*192\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,128,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,128,[1,7],scope='Conv2d_1b_1x7')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[7,1],scope='Conv2d_1c_7x1')\n",
    "                # branch 3: 1*1*128 [(7,1)*128,(1,7)*128,(7,1)*128,(1,7)*192]\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,128,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,128,[7,1],scope='Conv2d_1b_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,128,[1,7],scope='Conv2d_1c_1x7')\n",
    "                    branch_2 = slim.conv2d(branch_2,128,[7,1],scope='Conv2d_1d_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[1,7],scope='Conv2d_1e_1x7')\n",
    "                # branch 4: 3*3 avr pooling;1*1*192\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_1a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,192,[1,1],scope='Conv2d_1b_1x1')\n",
    "                # concate all 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            '''\n",
    "                第二个inception模组的第三个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_6c'):\n",
    "                # branch 1 1*1*192\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,192,[1,1],scope='Conv2d_1a_1x1')\n",
    "                # branch 2 1*1*128,1*7*128,7*1*192\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,160,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,160,[1,7],scope='Conv2d_1b_1x7')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[7,1],scope='Conv2d_1c_7x1')\n",
    "                # branch 3: 1*1*128 [(7,1)*128,(1,7)*128,(7,1)*128,(1,7)*192]\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,160,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,160,[7,1],scope='Conv2d_1b_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,160,[1,7],scope='Conv2d_1c_1x7')\n",
    "                    branch_2 = slim.conv2d(branch_2,160,[7,1],scope='Conv2d_1d_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[1,7],scope='Conv2d_1e_1x7')\n",
    "                # branch 4: 3*3 avr pooling;1*1*192\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_1a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,192,[1,1],scope='Conv2d_1b_1x1')\n",
    "                # concate all 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            \n",
    "            '''\n",
    "                第二个inception模组的第四个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_6d'):\n",
    "                # branch 1 1*1*192\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,192,[1,1],scope='Conv2d_1a_1x1')\n",
    "                # branch 2 1*1*128,1*7*128,7*1*192\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,160,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,160,[1,7],scope='Conv2d_1b_1x7')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[7,1],scope='Conv2d_1c_7x1')\n",
    "                # branch 3: 1*1*128 [(7,1)*128,(1,7)*128,(7,1)*128,(1,7)*192]\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,160,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,160,[7,1],scope='Conv2d_1b_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,160,[1,7],scope='Conv2d_1c_1x7')\n",
    "                    branch_2 = slim.conv2d(branch_2,160,[7,1],scope='Conv2d_1d_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[1,7],scope='Conv2d_1e_1x7')\n",
    "                # branch 4: 3*3 avr pooling;1*1*192\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_1a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,192,[1,1],scope='Conv2d_1b_1x1')\n",
    "                # concate all 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            \n",
    "            '''\n",
    "                第二个inception模组的第五个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_6e'):\n",
    "                # branch 1 1*1*192\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,192,[1,1],scope='Conv2d_1a_1x1')\n",
    "                # branch 2 1*1*128,1*7*128,7*1*192\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,192,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[1,7],scope='Conv2d_1b_1x7')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[7,1],scope='Conv2d_1c_7x1')\n",
    "                # branch 3: 1*1*128 [(7,1)*128,(1,7)*128,(7,1)*128,(1,7)*192]\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,192,[1,1],scope='Conv2d_1a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[7,1],scope='Conv2d_1b_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[1,7],scope='Conv2d_1c_1x7')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[7,1],scope='Conv2d_1d_7x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,192,[1,7],scope='Conv2d_1e_1x7')\n",
    "                # branch 4: 3*3 avr pooling;1*1*192\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_1a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,192,[1,1],scope='Conv2d_1b_1x1')\n",
    "                # concate all 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            \n",
    "            # 保存第二个inception模组的最后一个输出\n",
    "            end_points['Mixed_6e']=net\n",
    "            \n",
    "            '''\n",
    "                第三个inception模组的第一个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_7a'):\n",
    "                # branch 1:1*1*192,3*3*320,strides=2\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,192,[1,1],scope='Conv2d_2a_1x1')\n",
    "                    branch_0 = slim.conv2d(branch_0,320,[3,3],stride=2,padding='VALID',scope='Conv2d_2b_3x3')\n",
    "                # branch 2: 1*1*192,1*7*192,7*1*192,3*3*192 strides=2\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,192,[1,1],scope='Conv2d_2a_1x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[1,7],scope='Conv2d_2b_1x7')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[7,1],scope='Conv2d_2c_7x1')\n",
    "                    branch_1 = slim.conv2d(branch_1,192,[3,3],stride=2,padding='VALID',scope='Conv2d_2d_3x3')\n",
    "                # branch 3: 3*3 maxpool\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.max_pool2d(net,[3,3],stride=2,padding='VALID',scope='MaxPool_2a_3x3')\n",
    "                # concate all 3 branch\n",
    "                net = tf.concat([branch_0,branch_1,branch_2],3)\n",
    "            \n",
    "            '''\n",
    "                第三个inception模组的第二个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_7b'):\n",
    "                # branch_1 : 1*1*320\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,320,[1,1],scope='Conv2d_3a_1x1')\n",
    "                # branch_2 : 1*1*384 [1*3*384,3*1*384]\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,384,[1,1],scope='Conv2d_3a_1x1')\n",
    "                    branch_1 = tf.concat([slim.conv2d(branch_1,384,[1,3],scope='Conv2d_3a_1x3'),\n",
    "                                          slim.conv2d(branch_1,384,[3,1],scope='Conv2d_3a_3x1')],\n",
    "                                         axis=3)\n",
    "                # branch_3 : 1*1*448,3*3*384, [1*3*384,3*1*384]\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,448,[1,1],scope='Conv2d_3a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,384,[3,3],scope='Conv2d_3b_3x3')\n",
    "                    branch_2 = tf.concat([slim.conv2d(branch_2,384,[1,3],scope='Conv2d_3c_3x3'),\n",
    "                                          slim.conv2d(branch_2,384,[3,2],scope='Conv2d_3d_3x3')],\n",
    "                                         axis=3)\n",
    "                # branch_4 : 3*3 avr pooling,1*1*192\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_3a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,192,[1,1],scope='Conv2d_3b_1x1')\n",
    "                \n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "                \n",
    "            '''\n",
    "                第三个inception模组的第三个inception块\n",
    "            '''\n",
    "            with tf.variable_scope('Mixed_7c'):\n",
    "                # branch 1: 1*1*320\n",
    "                with tf.variable_scope('Branch_0'):\n",
    "                    branch_0 = slim.conv2d(net,320,[1,1],scope='Conv2d_4a_1x1')\n",
    "                # branch 2: 1*1*384 [(1*3*384),(3,1,384)]\n",
    "                with tf.variable_scope('Branch_1'):\n",
    "                    branch_1 = slim.conv2d(net,384,[1,1],scope='Conv2d_4a_1x1')\n",
    "                    branch_1 = tf.concat([slim.conv2d(branch_1,384,[1,3],scope='Conv2d_4b_1x3'),\n",
    "                                          slim.conv2d(branch_1,384,[3,1],scope='Conv2d_4c_3x1')],\n",
    "                                          axis=3)\n",
    "                # branch_3 : 1*1*448,3*3*384, [(1*3),(3*1)]*384\n",
    "                with tf.variable_scope('Branch_2'):\n",
    "                    branch_2 = slim.conv2d(net,448,[1,1],scope='Conv2d_4a_1x1')\n",
    "                    branch_2 = slim.conv2d(branch_2,384,[3,3],scope='Conv2d_4b_3x3')\n",
    "                    branch_2 = tf.concat([slim.conv2d(branch_2,384,[1,3],scope='Conv2d_4c_1x3'),\n",
    "                                          slim.conv2d(branch_2,384,[3,1],scope='Conv2d_4d_3x1')],\n",
    "                                          axis=3)\n",
    "                # branch 4 ：3x3 avr pool;1x1x192\n",
    "                with tf.variable_scope('Branch_3'):\n",
    "                    branch_3 = slim.avg_pool2d(net,[3,3],scope='AvgPool_4a_3x3')\n",
    "                    branch_3 = slim.conv2d(branch_3,192,[1,1],scope='Conv2d_4b_1x1')\n",
    "                # concate all 4 branches\n",
    "                net = tf.concat([branch_0,branch_1,branch_2,branch_3],axis=3)\n",
    "            \n",
    "            return net,end_points\n",
    "                    \n",
    "                \n",
    "                \n",
    "        \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inception_v3(inputs,\n",
    "                 num_classes=1000,\n",
    "                 is_training=True,\n",
    "                 dropout_keep_prob=0.8,\n",
    "                 prediction_fn=slim.softmax,\n",
    "                 spatial_squeeze=True,\n",
    "                 reuse=None,\n",
    "                 scope='InceptionV3'):\n",
    "    with tf.variable_scope(scope,'InceptionV3',[inputs,num_classes],reuse=reuse) as scope:\n",
    "        with slim.arg_scope([slim.batch_norm,slim.dropout],is_training=is_training):\n",
    "            net,end_points=inception_v3_base(inputs,scope=scope)\n",
    "            '''\n",
    "              超参数定义\n",
    "              辅助分类节点\n",
    "            '''\n",
    "            with slim.arg_scope([slim.conv2d,slim.max_pool2d,slim.avg_pool2d],stride=1,padding='SAME'):\n",
    "                aux_logits = end_points['Mixed_6e']\n",
    "                \n",
    "                with tf.variable_scope('AuxLogits'):\n",
    "                    aux_logits = slim.avg_pool2d(aux_logits,[5,5],stride=3,padding='VALID',scope='AvgPool_1a_5x5')\n",
    "                    aux_logits = slim.conv2d(aux_logits,128,[1,1],scope='Conv2d_1b_1x1')\n",
    "                    aux_logits = slim.conv2d(aux_logits,768,[5,5],weights_initializer=trunc_normal(0.01),padding='VALID',scope='Conv2d_2a_5x5')\n",
    "                    aux_logits = slim.conv2d(aux_logits,num_classes,[1,1],activation_fn=None,\n",
    "                                             normalizer_fn=None,weights_initializer=trunc_normal(0.001),scope='Conv2d_2b_1x1')\n",
    "                    if spatial_squeeze:\n",
    "                        aux_logits = tf.squeeze(aux_logits,[1,2],name='SpatialSqueeze')\n",
    "                    end_points['AuxLogits'] = aux_logits\n",
    "            '''\n",
    "                正常分类\n",
    "            '''\n",
    "            with tf.variable_scope('Logits'):\n",
    "                net = slim.avg_pool2d(net,[8,8],padding='VALID',scope='AvgPool_1a_8x8')\n",
    "                net = slim.dropout(net,keep_prob=dropout_keep_prob,scope='Dropout_1b')\n",
    "                end_points['PreLogits'] = net\n",
    "                logits = slim.conv2d(net,num_classes,[1,1],activation_fn=None,\n",
    "                                     normalizer_fn=None,scope='Conv2d_1c_1x1')\n",
    "                if spatial_squeeze:\n",
    "                    logits = tf.squeeze(logits,[1,2],name='SpatialSqueeze')\n",
    "            \n",
    "            # 保存各种节点\n",
    "            end_points['Logits'] = logits\n",
    "            end_points['Predictions'] = prediction_fn(logits,scope='Predictions')\n",
    "    return logits,end_points\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_tensorflow_run(session,target,info_string,num_batches):\n",
    "    num_steps_burn_in = 10\n",
    "    total_duration = 0.0\n",
    "    total_duration_squared=0.0\n",
    "    \n",
    "    for i in range(num_batches + num_steps_burn_in):\n",
    "        start_time = time.time()\n",
    "        _ = session.run(target)\n",
    "        # 持续时间\n",
    "        duration = time.time()-start_time\n",
    "        if i >= num_steps_burn_in:\n",
    "            if not i % 10 :\n",
    "                print('%s: step %d, duration = %.3f' % (datetime.now().strftime('%X'), \n",
    "                                                        i - num_steps_burn_in, \n",
    "                                                        duration))\n",
    "            total_duration += duration\n",
    "            total_duration_squared += duration*duration\n",
    "    \n",
    "    # 计算平均耗时\n",
    "    mn = total_duration / num_batches\n",
    "    vr = total_duration_squared / num_batches-mn*mn\n",
    "    sd = math.sqrt(vr)\n",
    "    \n",
    "    print('%s: %s across %d steps, %.3f +/- %.3f sec / batch' % (datetime.now().strftime('%X'),\n",
    "                                                                 info_string, \n",
    "                                                                 num_batches, \n",
    "                                                                 mn, sd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16:11:02: step 0, duration = 4.155\n",
      "16:11:44: step 10, duration = 4.165\n",
      "16:12:26: step 20, duration = 4.140\n",
      "16:13:07: step 30, duration = 4.143\n",
      "16:13:49: step 40, duration = 4.053\n",
      "16:14:33: step 50, duration = 4.624\n",
      "16:15:15: step 60, duration = 4.112\n",
      "16:15:58: step 70, duration = 4.198\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-3b34f6737d59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mnum_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtime_tensorflow_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Forward'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_batches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-62-4ce9c21b9530>\u001b[0m in \u001b[0;36mtime_tensorflow_run\u001b[1;34m(session, target, info_string, num_batches)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_batches\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnum_steps_burn_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[1;31m# 持续时间\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PY3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    903\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 905\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    906\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PY3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1135\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1137\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1138\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PY3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1353\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1354\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[1;32m-> 1355\u001b[1;33m                            options, run_metadata)\n\u001b[0m\u001b[0;32m   1356\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1357\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PY3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1359\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1360\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1361\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1362\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Python\\PY3.6\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m           return tf_session.TF_Run(session, options, feed_dict, fetch_list,\n\u001b[1;32m-> 1340\u001b[1;33m                                    target_list, status, run_metadata)\n\u001b[0m\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "log_dir='./logs/example5/'\n",
    "tf.reset_default_graph()\n",
    "batch_size = 32\n",
    "height,width = 299,299\n",
    "inputs = tf.random_uniform([batch_size,height,width,3])\n",
    "\n",
    "with slim.arg_scope(inception_v3_arg_scope()):\n",
    "    logits,end_points = inception_v3(inputs,is_training=False)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "\n",
    "\n",
    "num_batches = 100\n",
    "time_tensorflow_run(sess,logits,'Forward',num_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib.slim.python.slim.nets import inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inception??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
